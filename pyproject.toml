[project]
name = "uae_law_rag"
version = "0.1.0"
description = "Unified AI Development Project Template (Optimized for macOS)"
authors = [
    {name = "YOUR NAME", email = "your@email"}
]
requires-python = ">=3.11"
dependencies = [            
    "python-dotenv>=1.0.0",
    "pydantic-settings>=2.10.0",
    "requests>=2.31.0",
    "tqdm>=4.66.0",
    "ollama>=0.6.1",
    "modelscope>=1.32.0",
    "ruff>=0.14.6",
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "pytest-asyncio>=0.21.0",
    "pre-commit>=3.0.0",
    "mcp>=1.0.0",
    "chromadb>=1.3.7",
    "nltk>=3.9.2",
    "httpx[socks]>=0.28.1",
]

[dependency-groups]
jupyter = [
    "jupyter>=1.0.0",
    "ipykernel>=6.25.0",    
]

backend = [
    "fastapi>=0.104.0",
    "sqlalchemy>=2.0.45",
    "uvicorn>=0.38.0",
    "psycopg2-binary>=2.9.11",
    "redis>=5.0.0",
    "websockets>=12.0",
]

llamaindex-basic = [
    "llama-index>=0.12.52",
    "llama-index-embeddings-dashscope>=0.3.0",
    "llama-index-embeddings-ollama>=0.8",
    "llama-index-llms-dashscope>=0.4.1",    
    "llama-index-llms-ollama>=0.9.1",
    "llama-index-llms-deepseek>=0.2.0",
    "llama-index-readers-file>=0.4.8",
    "llama-index-vector-stores-chroma>=0.4.2", 
]

llamaindex-advance = [
    "llama-index-embeddings-huggingface>=0.6.1",
    "llama-index-llms-huggingface>=0.6.1",
    "llama-index-retrievers-bm25>=0.5.2",
]

db = [
    "pymilvus>=2.6.3",
]

eval = [
    "deepeval>=0.21.0",
    "ragas>=0.1.0",   
]

parsing = [
    "unstructured[local-inference]>=0.12.0",
    "pymupdf>=1.26.6",
]

llm-core = [
    "torch>=2.5.0",
    "transformers>=4.37.0",           
    "nltk>=3.9.2",
    
    "coremltools>=7.0",
    "onnx>=1.15.0",
    "onnxruntime>=1.17.0",  

    "accelerate>=0.26.0",
    "vllm>=0.4.0",
    "mlx>=0.13.0",
    "mlx-lm>=0.6.0",
    
    "bitsandbytes>=0.40.0",
    "peft>=0.10.0",
    
    "openai>=1.12.0",
    "litellm>=1.30.0",
    
    "trl>=0.7.0",
]

langchain-core = [
    "langchain>=1.1.0",        
    "langchain-community>=0.1.0",
    "langchain-core>=0.1.0",
    "langchain-qwq>=0.3.1",
    "langchain-deepseek>=1.0.1",
    "langchain-openai>=1.1.0",
    "langgraph>=1.0.0",
]

data-processing-core = [
    "numpy>=1.24.0",
    "pandas>=2.1.0",
    "scipy>=1.11.0",
    "scikit-learn>=1.3.0",
    "datasets>=2.16.0",
    
    "matplotlib>=3.7.0",
    "seaborn>=0.13.0",
    "plotly>=5.17.0",
    "wandb>=0.16.0",
]

multimodal-core = [
    "diffusers>=0.26.0",
    
    "opencv-python>=4.8.0",
    "pillow>=10.0.0",
    
    "librosa>=0.10.0",
    "soundfile>=0.12.0",
    
    "imageio>=2.31.0",
    "imageio-ffmpeg>=0.4.8",
    
    "controlnet-aux>=0.0.6",
]

qwen-agent-core = [
    "qwen-agent"
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"


[tool.ruff]
select = ["E", "F", "W"]
ignore = ["E402", "E501", "W291", "W292", "W293", "E203", "D"]
line-length = 120
exclude = ["*.toml"]

[tool.ruff.format]
quote-style = "double"
indent-style = "space"
line-ending = "lf"
exclude = ["*.toml"]
